---
title: 后台常见策略-负载均衡
date: 2024-03-23 23:43:59
tags: 后台常见策略
---

后台服务领域内有很多通用的策略，他们的本质往往很简单，只是长时间不接触就会被我遗忘掉。这里总结下负载均衡。

负载均衡有这么几种常见方式：

* round robin。 完全随机。
* 按权重随机。 比如一些纯计算的任务，他们完全不依赖缓存，对应服务也是无状态的；同时我们又因为开源节流的原因，使用了一些性能较差的机器，那么就适合以机器性能为权重，随机到服务节点。
* 一致性hash。 后台服务是有状态的，通常具有本地缓存，那么就适合使用一致性hash。

实战中我们都是使用一致性hash：在主调方的路由sdk内，建立hash值-虚拟节点-物理节点的映射关系。但是偶尔的，我们会遇到一些问题：
* 正常实现里，一个hash值总是对应一个物理节点。如果映射关系发生变化（机器上下线），就要承担流量迁移/重新建立缓存的开销。有时这个开销非常大，比如在推荐算法场景里，某个模型文件可能很大，重建一次要耗费很长时间（用于下载/解析）。为了减少开销，可以考虑一个hash值对应多个物理节点，然后随机路由到其中一个，这样可以使多台机器同时具有某个对象的缓存。具体怎么做呢？例如一个hash值本来对应虚拟节点X，现在路由的时候随机选区虚拟节点X-1/X/X+1，于是可以对应到3台物理节点。
* 有时候我们想做的很精细。比如节点上线时，要给它冷启动/预热的时间，那么就要分配对应的权重。本来一个物理节点对应N个虚拟节点，现在当机器上线时，我们先给他分配1个虚拟节点，然后按照一定时间间隔，慢慢地给它增加虚拟节点，直到冷启动完成（此时对应N个节点）。冷启动期间的节点变化节奏，还可以根据机器的接口耗时/成功率来变化，不过这就跟复杂了（有时候太复杂的东西实现起来容易出bug，建议不要瞎搞）。